{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8d710f-c953-4b87-8171-769a64488cc2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T16:02:54.086972Z",
     "iopub.status.busy": "2025-09-29T16:02:54.086215Z",
     "iopub.status.idle": "2025-09-29T16:02:54.091963Z",
     "shell.execute_reply": "2025-09-29T16:02:54.091058Z",
     "shell.execute_reply.started": "2025-09-29T16:02:54.086941Z"
    }
   },
   "outputs": [],
   "source": [
    "%%writefile requirements.txt\n",
    "strands-agents>=1.9.1\n",
    "strands-agents-tools>=0.2.8\n",
    "mlflow>=3.4.0\n",
    "mlflow-sagemaker>=1.5.11\n",
    "strands-agents[sagemaker]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f264f6c-59fb-47a4-9794-3c3b0ad72600",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T16:02:56.065983Z",
     "iopub.status.busy": "2025-09-29T16:02:56.065597Z",
     "iopub.status.idle": "2025-09-29T16:02:56.994652Z",
     "shell.execute_reply": "2025-09-29T16:02:56.993758Z",
     "shell.execute_reply.started": "2025-09-29T16:02:56.065945Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9634ad2-a018-4220-be26-11a9036fb3cd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-28T22:31:03.748269Z",
     "iopub.status.busy": "2025-09-28T22:31:03.747964Z",
     "iopub.status.idle": "2025-09-28T22:31:03.921136Z",
     "shell.execute_reply": "2025-09-28T22:31:03.920283Z",
     "shell.execute_reply.started": "2025-09-28T22:31:03.748243Z"
    }
   },
   "outputs": [],
   "source": [
    "cat requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7badde-eac2-4f58-acde-a30a0b701c20",
   "metadata": {},
   "source": [
    "## Beginning with Stands Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a7f52f-a5f7-424d-a73e-c72d7543bf9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T20:12:32.574340Z",
     "iopub.status.busy": "2025-09-30T20:12:32.573781Z",
     "iopub.status.idle": "2025-09-30T20:12:44.984962Z",
     "shell.execute_reply": "2025-09-30T20:12:44.984148Z",
     "shell.execute_reply.started": "2025-09-30T20:12:32.574310Z"
    }
   },
   "outputs": [],
   "source": [
    "from strands import Agent, tool\n",
    "from strands_tools import http_request, calculator\n",
    "from strands.models import BedrockModel\n",
    "\n",
    "model = BedrockModel(\n",
    "    model_id=\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\"\n",
    ")\n",
    "\n",
    "agent = Agent(model=model, tools=[http_request])\n",
    "agent(\"Where is the international space station now?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022f0356-416a-4a10-8bbd-0893958ace55",
   "metadata": {},
   "source": [
    "## Deploy Model as SageMaker AI Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fc3b33-5e90-4ecb-bf8f-be6ad725df09",
   "metadata": {
    "execution": {
     "iopub.status.busy": "2025-09-30T20:12:27.904325Z",
     "iopub.status.idle": "2025-09-30T20:12:27.904703Z",
     "shell.execute_reply": "2025-09-30T20:12:27.904535Z",
     "shell.execute_reply.started": "2025-09-30T20:12:27.904517Z"
    }
   },
   "outputs": [],
   "source": [
    "# Deploy initial endpoint with Qwen-4B\n",
    "import boto3\n",
    "from boto3.session import Session\n",
    "from sagemaker.jumpstart.model import JumpStartModel\n",
    "\n",
    "boto_session = Session()\n",
    "sts = boto3.client('sts')\n",
    "account_id = sts.get_caller_identity().get(\"Account\")\n",
    "region = boto_session.region_name\n",
    "\n",
    "ENDPOINT_NAME = INITIAL_CONFIG_NAME = \"llm-endpoint-sagemaker\" # We will keep using this endpoint name\n",
    "\n",
    "model_a = JumpStartModel(\n",
    "    model_id=\"huggingface-reasoning-qwen3-4b\", \n",
    "    model_version=\"1.0.0\",\n",
    "    name=\"qwen-4b-model\"\n",
    ")\n",
    "\n",
    "# Deploy the model to an endpoint\n",
    "predictor_a = model_a.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=\"ml.g5.2xlarge\",\n",
    "    endpoint_name=ENDPOINT_NAME\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e167d38e-429b-4b33-9362-8e08bcebe5d4",
   "metadata": {},
   "source": [
    "## Use SageMaker LLM endpoint with Strands Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54579d43-3faa-498b-897f-f789deb0af22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T19:45:18.781756Z",
     "iopub.status.busy": "2025-09-30T19:45:18.781442Z",
     "iopub.status.idle": "2025-09-30T19:45:51.385693Z",
     "shell.execute_reply": "2025-09-30T19:45:51.384371Z",
     "shell.execute_reply.started": "2025-09-30T19:45:18.781734Z"
    }
   },
   "outputs": [],
   "source": [
    "from strands.models.sagemaker import SageMakerAIModel\n",
    "from strands import Agent, tool\n",
    "from strands_tools import http_request, calculator\n",
    "\n",
    "model_sagemaker = SageMakerAIModel(\n",
    "    endpoint_config={\n",
    "        \"endpoint_name\": ENDPOINT_NAME,\n",
    "        \"region_name\": region\n",
    "    },\n",
    "    payload_config={\n",
    "        \"max_tokens\": 2048,\n",
    "        \"temperature\": 0.2,\n",
    "        \"stream\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Test the agent\n",
    "agent = Agent(model=model_sagemaker, tools=[http_request])\n",
    "agent(\"Where is the international space station now? (Use: http://api.open-notify.org/iss-now.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa949c8-3984-42a2-b711-931d5d25c2f1",
   "metadata": {},
   "source": [
    "## Creating MLflow Tracking Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a318c066-2c45-482c-9df8-b71c82a0fe29",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T15:35:37.737291Z",
     "iopub.status.busy": "2025-09-30T15:35:37.737039Z",
     "iopub.status.idle": "2025-09-30T15:35:39.244080Z",
     "shell.execute_reply": "2025-09-30T15:35:39.243245Z",
     "shell.execute_reply.started": "2025-09-30T15:35:37.737270Z"
    }
   },
   "outputs": [],
   "source": [
    "# MLflow config\n",
    "# It can be converted to create a new tracking server from code.\n",
    "import mlflow\n",
    "import os\n",
    "\n",
    "# Create MLflow tracking server\n",
    "response = sagemaker_client.create_mlflow_tracking_server(\n",
    "    TrackingServerName='strands-mlflow-server',\n",
    "    ArtifactStoreUri=f's3://{account_id}-mlflow-bucket/artifacts',\n",
    "    RoleArn=role,\n",
    "    TrackingServerSize='Small',  # Small, Medium, or Large\n",
    "    WeeklyMaintenanceWindowStart='Tue:03:30'\n",
    ")\n",
    "\n",
    "server_info = sagemaker_client.describe_mlflow_tracking_server(\n",
    "    TrackingServerName='strands-mlflow-server'\n",
    ")\n",
    "\n",
    "tracking_uri = server_info['TrackingServerArn']\n",
    "os.environ[\"MLFLOW_TRACKING_URI\"] = tracking_uri\n",
    "# Or you can set the tracking server as below.\n",
    "#mlflow.set_tracking_uri(tracking_uri)\n",
    "\n",
    "mlflow.set_tracking_uri(tracking_uri)\n",
    "print(f\"MLflow Tracking Server URL: {tracking_uri}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c68d89f-f3a0-41c4-bfd2-e5de5e3fde88",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T19:39:33.237684Z",
     "iopub.status.busy": "2025-09-30T19:39:33.237166Z",
     "iopub.status.idle": "2025-09-30T19:39:35.238181Z",
     "shell.execute_reply": "2025-09-30T19:39:35.237289Z",
     "shell.execute_reply.started": "2025-09-30T19:39:33.237656Z"
    }
   },
   "outputs": [],
   "source": [
    "# IF MLFLOW TRACKING SERVER ALREADY EXISTS, USE FOLLOWING CODE INSTEAD\n",
    "import mlflow\n",
    "tracking_uri = \"<TRACKING_SERVER_ARN>\"\n",
    "mlflow.set_tracking_uri(tracking_uri)\n",
    "print(f\"MLflow Tracking Server URL: {tracking_uri}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab5f401-2eee-466d-90b6-50c29d0edfdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T15:35:39.432211Z",
     "iopub.status.busy": "2025-09-30T15:35:39.431921Z",
     "iopub.status.idle": "2025-09-30T15:35:39.492714Z",
     "shell.execute_reply": "2025-09-30T15:35:39.491882Z",
     "shell.execute_reply.started": "2025-09-30T15:35:39.432189Z"
    }
   },
   "source": [
    "## Run the agent with MLflow tracing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab1cd55-3cec-42dc-9b90-624339bf551b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T20:12:57.755469Z",
     "iopub.status.busy": "2025-09-30T20:12:57.755174Z",
     "iopub.status.idle": "2025-09-30T20:12:59.211508Z",
     "shell.execute_reply": "2025-09-30T20:12:59.210935Z",
     "shell.execute_reply.started": "2025-09-30T20:12:57.755448Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create a new experiment and start logging\n",
    "import mlflow\n",
    "mlflow.set_experiment(\"Strands_Agents_prod\")\n",
    "mlflow.strands.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1144ccd-7492-4348-8714-fbd4f3a3025b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T20:13:03.043717Z",
     "iopub.status.busy": "2025-09-30T20:13:03.043257Z",
     "iopub.status.idle": "2025-09-30T20:13:03.142678Z",
     "shell.execute_reply": "2025-09-30T20:13:03.141394Z",
     "shell.execute_reply.started": "2025-09-30T20:13:03.043681Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the agent, and apply post-processing to the result\n",
    "from strands import Agent, tool\n",
    "\n",
    "def capitalize(response):\n",
    "    return response.upper()\n",
    "    \n",
    "agent = Agent(model=model_sagemaker, tools=[http_request])\n",
    "response = agent(\"Where is the international space station now? (Use: http://api.open-notify.org/iss-now.json\")\n",
    "capitalize(response.message['content'][0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa04bf3f-2d3f-4ef3-ba7b-31503408263f",
   "metadata": {},
   "source": [
    "## Explicit tracing using @mlflow.trace decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7ec50a-0e63-485f-aa5e-4e694f2b3b80",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T19:50:04.425982Z",
     "iopub.status.busy": "2025-09-30T19:50:04.423990Z",
     "iopub.status.idle": "2025-09-30T19:50:14.233784Z",
     "shell.execute_reply": "2025-09-30T19:50:14.233023Z",
     "shell.execute_reply.started": "2025-09-30T19:50:04.425942Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@mlflow.trace(span_type=\"func\", attributes={\"operation\": \"capitalize\"})\n",
    "def capitalize(response):\n",
    "    return response.upper()\n",
    "\n",
    "@mlflow.trace\n",
    "def run_agent():\n",
    "    agent = Agent(tools=[http_request])\n",
    "    response = agent(\"Where is the international space station now?\")\n",
    "    capitalized_response = capitalize(response.message['content'][0]['text'])\n",
    "\n",
    "    return capitalized_response\n",
    "\n",
    "# Execute the traced function\n",
    "capitalized_response = run_agent()\n",
    "print(capitalized_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92cb042e-c9f6-43a3-bf04-b4482d655b9b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-29T21:06:59.753712Z",
     "iopub.status.busy": "2025-09-29T21:06:59.753295Z",
     "iopub.status.idle": "2025-09-29T21:17:32.223135Z",
     "shell.execute_reply": "2025-09-29T21:17:32.222104Z",
     "shell.execute_reply.started": "2025-09-29T21:06:59.753687Z"
    }
   },
   "source": [
    "## Deploy a new LLM for A/B testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcf6042-e410-48e6-8e6e-2888d530de58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T20:17:32.634685Z",
     "iopub.status.busy": "2025-09-30T20:17:32.633890Z",
     "iopub.status.idle": "2025-09-30T20:17:33.878892Z",
     "shell.execute_reply": "2025-09-30T20:17:33.877876Z",
     "shell.execute_reply.started": "2025-09-30T20:17:32.634652Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step1: Create a model from JumpStart\n",
    "import boto3\n",
    "from sagemaker.jumpstart.model import JumpStartModel\n",
    "model_b_name  =\"sagemaker-strands-demo-qwen3-8b\"\n",
    "model_b_id, model_b_version = \"huggingface-reasoning-qwen3-8b\", \"1.0.0\"\n",
    "\n",
    "model_b = JumpStartModel(\n",
    "    model_id=\"huggingface-reasoning-qwen3-8b\",  \n",
    "    model_version=\"1.0.0\",\n",
    "    name=model_b_name\n",
    ")\n",
    "model_b.create(instance_type=\"ml.g5.2xlarge\")\n",
    "\n",
    "# Step2: Create production variants for A/B testing\n",
    "# Create production variants for A/B testing\n",
    "production_variants = [\n",
    "   # The original model (champion)\n",
    "   {\n",
    "        \"VariantName\": \"qwen-4b-variant\",\n",
    "        \"ModelName\": \"qwen-4b-model\",\n",
    "        \"InitialInstanceCount\": 1,\n",
    "        \"InstanceType\": \"ml.g5.2xlarge\",\n",
    "        \"InitialVariantWeight\": 0.5  # It will take 50% of the traffic\n",
    "    },\n",
    "   # The new model (challenger)\n",
    "    {\n",
    "        \"VariantName\": \"qwen-8b-variant\",\n",
    "        \"ModelName\": model_b_name,\n",
    "        \"InitialInstanceCount\": 1,\n",
    "        \"InstanceType\": \"ml.g5.2xlarge\",\n",
    "        \"InitialVariantWeight\": 0.5  # It will take 50% of the traffic\n",
    "    }\n",
    "]\n",
    "\n",
    "# Step3: Create new endpoint configuration\n",
    "sagemaker_client = boto3.client('sagemaker')\n",
    "ENDPOINT_CONFIG_AB_TESTING = \"llm-endpoint-config-ab\"\n",
    "sagemaker_client.create_endpoint_config(\n",
    "    EndpointConfigName=ENDPOINT_CONFIG_AB_TESTING,\n",
    "    ProductionVariants=production_variants\n",
    ")\n",
    "\n",
    "# Step4: Update the endpoint with new A/B testing configuration\n",
    "sagemaker_client.update_endpoint(\n",
    "    EndpointName=ENDPOINT_NAME, #Remember, the endpoint name stays the same\n",
    "    EndpointConfigName=ENDPOINT_CONFIG_AB_TESTING\n",
    ")\n",
    "\n",
    "# Wait until the update is completed\n",
    "waiter = boto3.client('sagemaker').get_waiter('endpoint_in_service')\n",
    "waiter.wait(EndpointName=ENDPOINT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b32777-5a1a-4a04-8d10-e5a795eec59d",
   "metadata": {},
   "source": [
    "## Controlled experiment using explicit variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4194f8b8-59d2-493e-9a6f-1e30b93d8bf6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T20:15:47.762365Z",
     "iopub.status.busy": "2025-09-30T20:15:47.761787Z",
     "iopub.status.idle": "2025-09-30T20:15:47.921635Z",
     "shell.execute_reply": "2025-09-30T20:15:47.920921Z",
     "shell.execute_reply.started": "2025-09-30T20:15:47.762340Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create SaegMaker models for A/B testing\n",
    "from strands.models.sagemaker import SageMakerAIModel\n",
    "from strands import Agent, tool\n",
    "from strands_tools import http_request, calculator\n",
    "\n",
    "model_sagemaker_a = SageMakerAIModel(\n",
    "    endpoint_config={\n",
    "        \"endpoint_name\": ENDPOINT_NAME,\n",
    "        \"region_name\": region,\n",
    "        \"target_variant\":\"qwen-4b-variant\"\n",
    "    },\n",
    "    payload_config={\n",
    "        \"max_tokens\": 2048,\n",
    "        \"temperature\": 0.2,\n",
    "        \"stream\": True,\n",
    "    }\n",
    ")\n",
    "\n",
    "model_sagemaker_b = SageMakerAIModel(\n",
    "    endpoint_config={\n",
    "        \"endpoint_name\": ENDPOINT_NAME,\n",
    "        \"region_name\": region,\n",
    "        \"target_variant\":\"qwen-8b-variant\"\n",
    "    },\n",
    "    payload_config={\n",
    "        \"max_tokens\": 2048,\n",
    "        \"temperature\": 0.2,\n",
    "        \"stream\": True,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecca2069-6316-49d2-a6e9-14b578901f16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T20:15:57.910443Z",
     "iopub.status.busy": "2025-09-30T20:15:57.909746Z",
     "iopub.status.idle": "2025-09-30T20:16:52.678791Z",
     "shell.execute_reply": "2025-09-30T20:16:52.677988Z",
     "shell.execute_reply.started": "2025-09-30T20:15:57.910414Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "mlflow.set_experiment(\"Strands_Agents_AB_testing\") # Start a new experiement\n",
    "\n",
    "with mlflow.start_span(): # For \"A\" variant.\n",
    "    mlflow.update_current_trace(tags={\"variant\": \"qwen-4b\"})\n",
    "    agent = Agent(model=model_sagemaker_a, tools=[http_request])\n",
    "    agent(\"Where is the international space station now. (Use: http://api.open-notify.org/iss-now.json)\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "#time.sleep(5) # Pause shortly before running the other variant.\n",
    "\n",
    "with mlflow.start_span(): # For \"B\" variant.\n",
    "    mlflow.update_current_trace(tags={\"variant\": \"qwen-8b\"})\n",
    "    agent = Agent(model=model_sagemaker_b, tools=[http_request])\n",
    "    agent(\"Where is the international space station now. (Use: http://api.open-notify.org/iss-now.json)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fef224-1500-42a1-8641-e8577bef3ea5",
   "metadata": {},
   "source": [
    "## Transition to the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d889930a-d569-4427-91c5-47fb5edf48ea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T20:17:53.362060Z",
     "iopub.status.busy": "2025-09-30T20:17:53.361778Z",
     "iopub.status.idle": "2025-09-30T20:17:54.261972Z",
     "shell.execute_reply": "2025-09-30T20:17:54.261256Z",
     "shell.execute_reply.started": "2025-09-30T20:17:53.362041Z"
    }
   },
   "outputs": [],
   "source": [
    "production_variants = [\n",
    "    {\n",
    "        \"VariantName\": \"qwen-8b-variant\",\n",
    "        \"ModelName\": model_b_name,\n",
    "        \"InitialInstanceCount\": 1,\n",
    "        \"InstanceType\": \"ml.g5.2xlarge\",\n",
    "        \"InitialVariantWeight\": 1\n",
    "    }\n",
    "]\n",
    "\n",
    "# Create new endpoint configuration\n",
    "NEW_ENDPOINT_CONFIG = \"llm-endpoint-config-qwen-8b\"\n",
    "sagemaker_client.create_endpoint_config(\n",
    "    EndpointConfigName=NEW_ENDPOINT_CONFIG,\n",
    "    ProductionVariants=production_variants\n",
    ")\n",
    "\n",
    "\n",
    "# Update the endpoint to use new configuration\n",
    "sagemaker_client.update_endpoint(\n",
    "    EndpointName=ENDPOINT_NAME,\n",
    "    EndpointConfigName=NEW_ENDPOINT_CONFIG\n",
    ")\n",
    "# Wait until the update is completed\n",
    "waiter = boto3.client('sagemaker').get_waiter('endpoint_in_service')\n",
    "waiter.wait(EndpointName=ENDPOINT_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1df0d90-fcfd-40a3-9aaf-838770cd1b45",
   "metadata": {},
   "source": [
    "## Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779f503f-cf7e-4e58-b599-1ee2c85fc665",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-09-30T20:18:18.447808Z",
     "iopub.status.busy": "2025-09-30T20:18:18.447521Z",
     "iopub.status.idle": "2025-09-30T20:18:18.614707Z",
     "shell.execute_reply": "2025-09-30T20:18:18.613710Z",
     "shell.execute_reply.started": "2025-09-30T20:18:18.447787Z"
    }
   },
   "outputs": [],
   "source": [
    "sagemaker_client.delete_endpoint(EndpointName=ENDPOINT_NAME)\n",
    "sagemaker_client.delete_endpoint_config(EndpointConfigName=INITIAL_CONFIG_NAME)\n",
    "sagemaker_client.delete_endpoint_config(EndpointConfigName=ENDPOINT_CONFIG_AB_TESTING)\n",
    "sagemaker_client.delete_endpoint_config(EndpointConfigName=NEW_ENDPOINT_CONFIG)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
